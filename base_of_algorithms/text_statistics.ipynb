{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextStatistics:\n",
    "    def __init__(self):\n",
    "        self.text = \"\"\n",
    "        self.words = []\n",
    "        self.letters = ()\n",
    "        self.frequency = {}\n",
    "        self.bilingual_words = []\n",
    "        \n",
    "    # текст из файла\n",
    "    def get_text(self, file_path: str) -> str:\n",
    "        with open(file_path, 'r', encoding='UTF-8') as file:\n",
    "            self.text = file.read()\n",
    "        \n",
    "    # слова из текста\n",
    "    def get_words(self) -> list:\n",
    "        self.words = re.findall(r'\\w+', self.text)\n",
    "        return self.words\n",
    "    \n",
    "    # количество слов\n",
    "    def words_amount(self) -> int:\n",
    "        return len(self.words)\n",
    "    \n",
    "    # буквы из слов\n",
    "    def get_letters(self) -> tuple:\n",
    "        self.letters =  tuple(\"\".join(self.words))\n",
    "        return self.letters\n",
    "    \n",
    "    # количество букв и их частоту\n",
    "    def letters_frequency(self) -> dict:\n",
    "        split_text = \"\".join(self.words)\n",
    "\n",
    "        for letter in self.letters:\n",
    "            f_letter = split_text.count(letter)\n",
    "            p_letter = 0\n",
    "            for w in self.words:\n",
    "                if letter in w:\n",
    "                    p_letter += 1\n",
    "            self.frequency[letter] = (f_letter, p_letter)\n",
    "            \n",
    "        return self.frequency\n",
    "        \n",
    "    # количество параграфов\n",
    "    def paragraph_amount(self) -> int:\n",
    "        return self.text.count(\"\\n\\n\")\n",
    "    \n",
    "    # слова с включающие буквы из разных алфавитов\n",
    "    def bilingual_word_amount(self) -> int:\n",
    "        for w in self.words:\n",
    "            if re.search(r'[a-zA-Z]', w) and re.search(r'[а-яА-Я]', w):\n",
    "                self.bilingual_words.append(w)   \n",
    "                  \n",
    "        return self.bilingual_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_statistics(file_path: str) -> tuple:\n",
    "    ts = TextStatistics()\n",
    "    ts.get_text(file_path)\n",
    "    ts.get_words()\n",
    "    ts.get_letters()\n",
    "    \n",
    "    w_amount = ts.words_amount()\n",
    "    l_frequency = ts.letters_frequency()\n",
    "    p_amount = ts.paragraph_amount()\n",
    "    b_words = ts.bilingual_word_amount()\n",
    "    \n",
    "    text_statistics = {}\n",
    "    \n",
    "    for key, value in l_frequency.items():\n",
    "        text_statistics[key] = value\n",
    "    \n",
    "    text_statistics[\"word_amount\"] = w_amount\n",
    "    text_statistics[\"paragraph_amount\"] = p_amount\n",
    "    text_statistics[\"bilingual_word_amount\"] = len(b_words)\n",
    "    \n",
    "    return text_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'П': (2, 2),\n",
       " 'р': (50, 42),\n",
       " 'о': (125, 93),\n",
       " 'с': (55, 49),\n",
       " 'т': (72, 60),\n",
       " 'ы': (21, 20),\n",
       " 'е': (70, 58),\n",
       " 'ч': (13, 13),\n",
       " 'и': (89, 79),\n",
       " 'л': (46, 44),\n",
       " 'а': (74, 53),\n",
       " 'в': (44, 40),\n",
       " 'з': (25, 25),\n",
       " 'д': (35, 33),\n",
       " 'н': (65, 53),\n",
       " 'м': (31, 30),\n",
       " 'п': (31, 31),\n",
       " 'Н': (2, 2),\n",
       " 'б': (16, 15),\n",
       " 'х': (10, 9),\n",
       " 'm': (7, 4),\n",
       " 'b': (2, 2),\n",
       " 'ь': (18, 17),\n",
       " 'ф': (7, 7),\n",
       " 'у': (23, 22),\n",
       " 'к': (36, 32),\n",
       " 'ц': (15, 15),\n",
       " 'ю': (10, 10),\n",
       " 'p': (3, 3),\n",
       " 'r': (6, 3),\n",
       " 'i': (6, 6),\n",
       " 'e': (7, 6),\n",
       " '_': (5, 3),\n",
       " 'n': (11, 7),\n",
       " 'u': (4, 4),\n",
       " 's': (4, 4),\n",
       " 'l': (4, 4),\n",
       " 'o': (6, 5),\n",
       " 'w': (2, 2),\n",
       " 'h': (4, 2),\n",
       " 'g': (2, 2),\n",
       " 'г': (6, 6),\n",
       " 'ж': (6, 6),\n",
       " 'я': (21, 18),\n",
       " 'й': (13, 13),\n",
       " 'э': (3, 3),\n",
       " 'Ф': (2, 2),\n",
       " 'щ': (7, 7),\n",
       " 'a': (4, 2),\n",
       " 't': (8, 4),\n",
       " 'Р': (1, 1),\n",
       " 'ш': (4, 4),\n",
       " 'N': (1, 1),\n",
       " 'Д': (2, 2),\n",
       " 'В': (1, 1),\n",
       " 'y': (1, 1),\n",
       " 'Г': (1, 1),\n",
       " 'Э': (1, 1),\n",
       " 'word_amount': 171,\n",
       " 'paragraph_amount': 3,\n",
       " 'bilingual_word_amount': 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_statistics(\"../test_data/statistics.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
